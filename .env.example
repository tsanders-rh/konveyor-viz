# Konveyor Visual Analysis Tool - Environment Variables
# Copy this file to .env and add your API keys

# ===================================
# LLM Provider Configuration
# ===================================
# Enable AI-powered insights by configuring one of the providers below.
# If no API key is provided, the tool will use rule-based analysis.

# --- Anthropic (Claude) ---
# Get your API key from: https://console.anthropic.com/
# VITE_ANTHROPIC_API_KEY=sk-ant-xxxxx
# VITE_ANTHROPIC_MODEL=claude-3-5-sonnet-20241022  # Optional, defaults to this

# --- OpenAI (GPT) ---
# Get your API key from: https://platform.openai.com/api-keys
# VITE_OPENAI_API_KEY=sk-xxxxx
# VITE_OPENAI_MODEL=gpt-4o  # Optional, defaults to gpt-4o

# --- Ollama (Local) ---
# Install Ollama from: https://ollama.ai
# Make sure Ollama is running locally
# VITE_OLLAMA_BASE_URL=http://localhost:11434
# VITE_OLLAMA_MODEL=llama2  # Or llama3, mistral, etc.

# ===================================
# Priority Order
# ===================================
# If multiple providers are configured, the tool will use:
# 1. Anthropic (Claude) - if VITE_ANTHROPIC_API_KEY is set
# 2. OpenAI (GPT) - if VITE_OPENAI_API_KEY is set
# 3. Ollama (Local) - if VITE_OLLAMA_BASE_URL is set
# 4. Rule-based - if none are configured

# ===================================
# Usage
# ===================================
# 1. Copy this file: cp .env.example .env
# 2. Add your API key for at least one provider
# 3. Restart the development server: npm run dev
# 4. Toggle AI mode in the Insights panel
